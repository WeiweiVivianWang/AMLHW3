{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI:  ww2439\n",
    "* Name: Weiwei Wang\n",
    "\n",
    "### Team Member 2 :\n",
    "* UNI: zs2319 \n",
    "* Name: Zhengyuan Shi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "\n",
    "# Fetch Data \n",
    "data_raw = pd.read_csv(\"/Users/weiweiwang/Desktop/AML1/HW3/data.csv\")\n",
    "#data_holdout_raw = pd.read_csv(\"/Users/weiweiwang/Desktop/AML1/HW3/holdout.csv\")\n",
    "\n",
    "data_holdout_raw = pd.read_csv(\"homework-iii-WeiweiVivianWang/data/holdout.csv\")\n",
    "# Split Data into X and y\n",
    "X = data_raw.drop('subscribed', axis=1)\n",
    "y = data_raw['subscribed']\n",
    "y.replace(to_replace = \"yes\", value = 1, inplace = True)\n",
    "y.replace(to_replace = \"no\", value = 0, inplace = True)\n",
    "\n",
    "# Define Parameters \n",
    "random_state = 7\n",
    "test_size = 0.25\n",
    "\n",
    "# Split Data into Random Training and Test Subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "#holdout\n",
    "\n",
    "X_holdout = data_holdout_raw.drop('ID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recode Missing Values \n",
    "def recode_NA(X):\n",
    "    \"\"\"Returns X with missing values coded as NaNs\"\"\"\n",
    "    #Index of Features where NA = \"unknown\"\n",
    "    j = []\n",
    "    j.extend(range(1, 7))\n",
    "    \n",
    "    for i in j:\n",
    "        X.iloc[:, i].replace(to_replace=\"unknown\", value=np.nan, inplace=True)\n",
    "     \n",
    "    #Feature where NA = \"nonexistent\"\n",
    "    X.iloc[:, 14].replace(to_replace=\"nonexistent\", value=np.nan, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "##feature selection\n",
    "def select_features(X):\n",
    "    \"\"\"Returns a subset of X\n",
    "    \n",
    "    Remove features that are irrelavent.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove Selected Features\n",
    "    X.drop(X.columns[10], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-Hot-Encoding get dummy variables\n",
    "def encode_OH(X):\n",
    "    \"\"\"Returns X with categorical features encoded as one-hot\"\"\"\n",
    "\n",
    "    #List of column names for continuous variables\n",
    "    list_con = [\"age\",\"campaign\",\"prev_days\",\"prev_contacts\",\"emp_var_rate\",\"cons_price_idx\",\"cons_conf_idx\",\n",
    "               \"euribor3m\",\"nr_employed\"] \n",
    "    \n",
    "    #List of column names for categorical variables\n",
    "    list_cat = ['job', 'marital_status', 'education', 'credit_default', 'housing', 'loan', 'contact',\n",
    "       'month', 'day_of_week', 'prev_outcomes']\n",
    "    \n",
    "    return pd.get_dummies(X, columns = list_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = recode_NA(X_train)\n",
    "X_train = select_features(X_train)\n",
    "X_train = encode_OH(X_train)\n",
    "X_test = recode_NA(X_test)\n",
    "X_test = select_features(X_test)\n",
    "X_test = encode_OH(X_test)\n",
    "\n",
    "X_holdout = recode_NA(X_holdout)\n",
    "X_holdout = select_features(X_holdout)\n",
    "X_holdout = encode_OH(X_holdout)\n",
    "X_holdout.insert(31, 'credit_default_yes', 0)\n",
    "\n",
    "\n",
    "X_whole = recode_NA(X)\n",
    "X_whole = select_features(X)\n",
    "X_whole = encode_OH(X)\n",
    "y_whole = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "random_state = 0\n",
    "test_size = 0.25\n",
    "cv = ShuffleSplit(n_splits=10, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78362432208736321"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logistic = LogisticRegressionCV(class_weight='balanced')\n",
    "#logistic = logistic.fit(X_train,y_train)\n",
    "logistic = logistic.fit(X_train,y_train)\n",
    "\n",
    "logistic.predict(X_test)\n",
    "\n",
    "\n",
    "result_holdout = logistic.predict_proba(X_test)[:,1]\n",
    "result_test_predict = logistic.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, result_test_predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = result_holdout\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71146996347808966"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###SVM\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import roc_auc_score\n",
    "model_svm=make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "model_svm.fit(X_train,y_train)\n",
    "svm_prob=model_svm.predict_proba(X_test)\n",
    "roc_auc_score(y_test,svm_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_result_holdout = model_svm.predict_proba(X_holdout)[:,1]\n",
    "#svm_result_test_predict = model_svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = svm_result_holdout\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74480402030409842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "QDA = make_pipeline(StandardScaler(), QuadraticDiscriminantAnalysis())\n",
    "#QDA.fit(X_train, y_train)\n",
    "QDA.fit(X_whole, y_whole)\n",
    "QDA.predict(X_test)\n",
    "QDA_prob = QDA.predict_proba(X_test)\n",
    "roc_auc_score(y_test,QDA_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818061271148\n"
     ]
    }
   ],
   "source": [
    "##Nerual Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = make_pipeline(StandardScaler(), MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1))\n",
    "MLP.fit(X_whole, y_whole)\n",
    "MLP.predict(X_test)\n",
    "MLP_prob = MLP.predict_proba(X_test)\n",
    "nn_score = roc_auc_score(y_test,MLP_prob[:,1])\n",
    "print (nn_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_result_holdout = MLP.predict_proba(X_holdout)[:,1]\n",
    "#nn_result_test_predict = MLP.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = nn_result_holdout\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78698277508638503"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\n",
    "LDA.fit(X_whole, y_whole)\n",
    "LDA.predict(X_test)\n",
    "LDA_prob = LDA.predict_proba(X_test)\n",
    "roc_auc_score(y_test,LDA_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_result_holdout = LDA.predict_proba(X_holdout)[:,1]\n",
    "#nn_result_test_predict = MLP.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = lda_result_holdout\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75102366978636703"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write code below, you can make multiple cells\n",
    "\n",
    "##Random forest without grid search\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.predict(X_test)\n",
    "rf_prob = rf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test,rf_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "###Random forest with grid search\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Build a classification task using 3 informative features\n",
    "#X, y = make_classification(n_samples=1000,\n",
    "#                           n_features=10,\n",
    "#                           n_informative=3,\n",
    "#                           n_redundant=0,\n",
    "#                           n_repeated=0,\n",
    "#                           n_classes=2,\n",
    "#                           random_state=0,\n",
    "#                           shuffle=False)\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77626017954194237"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=100, oob_score = True) \n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.predict(X_test)\n",
    "rfc_prob = rfc.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test,rfc_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78977350338305174"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb.predict(X_test)\n",
    "xgb_prob = xgb.predict_proba(X_test)\n",
    "roc_auc_score(y_test,xgb_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_whole, y_whole)\n",
    "xgb.predict(X_holdout)\n",
    "xgb_prob = xgb.predict_proba(X_holdout)\n",
    "roc_auc_score(y_test,xgb_prob[:,1])\n",
    "\n",
    "xgb_result_holdout = xgb.predict_proba(X_holdout)[:,1]\n",
    "xgb_result_test_predict = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = xgb_result_holdout\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78570052901784426"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.predict(X_test)\n",
    "ada_prob = ada.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, ada_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768575819138407"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ext = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "ext.fit(X_train, y_train)\n",
    "ext.predict(X_test)\n",
    "ext_prob = ext.predict_proba(X_test)\n",
    "roc_auc_score(y_test, ext_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79405166027099139"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(max_depth = 8, \n",
    "                                n_estimators = 120, \n",
    "                                learning_rate = 0.05, \n",
    "                                max_features = 'sqrt', \n",
    "                                min_samples_split = 500, \n",
    "                                min_samples_leaf=50)\n",
    "\n",
    "\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "gb.predict(X_test)\n",
    "gb_prob = gb.predict_proba(X_test)\n",
    "roc_auc_score(y_test, gb_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(max_depth = 8, \n",
    "                                n_estimators = 120, \n",
    "                                learning_rate = 0.05, \n",
    "                                max_features = 'sqrt', \n",
    "                                min_samples_split = 500, \n",
    "                                min_samples_leaf=50)\n",
    "gb.fit(X_whole, y_whole)\n",
    "gb.predict(X_holdout)\n",
    "gb_prob = gb.predict_proba(X_holdout)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = gb_prob\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79117541514009715"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Model averaging--voting classifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting1 = VotingClassifier([('Gradient Boosting',gb),\n",
    "                           ('Neural Network',MLP),\n",
    "                          ('LDA',LDA)],voting = 'soft')\n",
    "\n",
    "voting1.fit(X_train,y_train)\n",
    "voting1_prob = voting1.predict_proba(X_test)\n",
    "roc_auc_score(y_test, voting1_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Geting prediction probability for holdout set.\n",
    "\n",
    "voting1.fit(X_whole, y_whole)\n",
    "voting1.predict(X_holdout)\n",
    "voting1_prob = voting1.predict_proba(X_holdout)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = voting1_prob\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790488097098506"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[gb,\n",
    "                                       MLP,\n",
    "                                       LDA],\n",
    "                          meta_classifier=MLP)\n",
    "\n",
    "\n",
    "sclf.fit(X_train,y_train)\n",
    "\n",
    "sclf_prob = sclf.predict_proba(X_test)\n",
    "roc_auc_score(y_test, sclf_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Creative method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Resampling Techniques\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "\n",
    "rus = RandomUnderSampler(replacement = False)\n",
    "X_train_subsample, y_train_subsample = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversample, y_train_oversample = ros.fit_sample(X_train,y_train)\n",
    "resample_pipe = make_imb_pipeline(RandomOverSampler(), GradientBoostingClassifier(random_state = 22))\n",
    "param_grid = {'gradientboostingclassifier__n_estimators':[100,200],\n",
    "              'gradientboostingclassifier__max_depth':[2,4,6,8,10],\n",
    "              'gradientboostingclassifier__max_features':['auto','sqrt','log2']}\n",
    "\n",
    "resamp_model = GridSearchCV(estimator = resample_pipe,\n",
    "                           param_grid = param_grid,\n",
    "                           cv = 5, \n",
    "                           refit = True)\n",
    "resamp_model.fit(X_train, y_train)\n",
    "resamp_prob = resamp_model.predict_proba(X_test)[:,1]\n",
    "RAscore_resamp = roc_auc_score(y_test, resamp_prob)\n",
    "print(RAscore_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resamp_model.fit(X_whole, y_whole)\n",
    "resamp_prob = resamp_model.predict_proba(X_holdout)[:,1]\n",
    "\n",
    "test_hold = pd.read_csv('holdout.csv')\n",
    "test_hold['subscribed'] = resamp_prob\n",
    "test_hold.to_csv('sub_holdout.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradientboostingclassifier__max_depth': 2, 'gradientboostingclassifier__max_features': 'auto', 'gradientboostingclassifier__n_estimators': 268}\n"
     ]
    }
   ],
   "source": [
    "RAscore_resamp\n",
    "print (resamp_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "##Since the max score comes from neural network, we assert that roc_auc score >= 0.78.\n",
    "assert nn_score >= 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
